# FactGuard: Leveraging Multi-Agent Systems to GenerateAnswerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction


This repository contains the code and resources for the paper "FactGuard: Leveraging Multi-Agent Systems to Generate Answerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction". The paper introduces a novel multi-agent framework for generating answerable and unanswerable questions, and presents the FactGuard-Bench dataset, a benchmark designed to evaluate the performance of large language models (LLMs) in handling information extraction within extended contexts.


## Overview
The repository includes:

* Code: Implementation of the FactGuard framework for generating answerable and unanswerable questions.
* Data: The FactGuard-Bench dataset, which contains 25,220 examples of both answerable and unanswerable questions with context lengths ranging from 0 to 128K tokens.
* Experiments: Scripts and configurations for evaluating LLMs on the FactGuard-Bench dataset.
FactGuard Framework

## Install

```
git clone https://github.com/FactGuard/FactGuardBench.git
pip install FactGuardBench
```

### Note: During the double-blind review process, we only uploaded sample data and code.